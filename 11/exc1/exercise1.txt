1. Obtain a performance profile of the given application:
-Modify the compilation flags in the Makefile to include gprof instrumentation. We need to add the `-pg` flag to the `CC_FLAGS` in the `Makefile`.
-Run the application to generate the `gmon.out` profile data with `./real`.
-Run gprof to generate the performance analysis file with `gprof real gmon.out > analysis.txt`.

2. Discussion about the the performance profile, what information does it hold and how/why is this useful?
-The performance profile generated by `gprof` provides detailed insights into where the program spent most of its execution time and which functions are the most expensive.
-The flat profile lists functions sorted by the percentage of the total runtime they consumed:
	1. 46.78%: The `resid` fucntion is consuming nearly half of the total execution time and is a prime candidate for optimization.
	2. 19.03%: The `psinv` fucntion also consumes almost one-fifth of the total runtime. 
	3-5: ~10% The `interp`, `vranlc` and `rprj3` function all consume around 10% of time and can also be benefitly from parallelization. Noteworthy is that the `vranlc` fucntion is called a very large number of times and there might be also an improvment in minimazing the number of fucntion calls. 
	6: 3.48% The `norm2u3` less critical, further optimization could involve some parallelization.
-The call graph provides additional context on how functions interact and the hierarchical structure of function calls.
	`mg3P.constprop.2` seems to be a main or governing function making calls to other important functions (resid, psinv, rprj3, interp).
-Action Plan:
	1. Parallelize High-Cost Functions: Focus on `resid` and `psinv` first as they consume the majority of the time.
	2. Profile After Optimization: After parallelizing the high-cost functions, generate new performance profiles to observe the improvement and identify additional bottlenecks.
-The performance profile helps identify where the execution time is predominantly spent and guides us to target specific functions for optimization through parallelization. This systematic approach ensures resources are focused on high-impact areas, maximizing the performance gains from parallelization.


