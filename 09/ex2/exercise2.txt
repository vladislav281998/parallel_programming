Observations:
- Auto-Vectorization and OpenMP are nearly identical in performance.

Correctness Confirmation:
- Is the result still correct? Yes.

Findings on converting double to float precision:
- Execution time for the double precision version is notably longer than the single precision version. This is due to the increased CPU resource demand of double precision operations, which involve larger data sizes and more complex arithmetic.
- The difference in the `perf stat` event counts for the floating point and double precision versions of your code stems from how single-precision (`float`) and double-precision (`double`) data are processed using SSE2 instructions:

  1. Vectorization Efficiency: SSE2 instructions process `floats` and `doubles` differently. Each SSE2 vector register is 128 bits wide, capable of holding four `floats` or two `doubles`. Thus, operations on `floats` can handle twice as many elements simultaneously compared to `doubles`.=
  2. Instruction Use and Count: The event `FP_COMP_OPS_EXE.SSE2_INTEGER` likely counts operations differently based on the instruction mix generated by the compiler for `floats` vs. `doubles`. The use of `#pragma omp simd` encourages the compiler to use SIMD instructions, but the generated instructions can vary significantly between data types due to their size and the specific optimizations the compiler applies.
  3. Hardware Event Counting: The specific method used by the hardware to count floating-point operations might inherently count more operations when dealing with `doubles` due to either the increased number of instructions needed to process the same number of elements or the internal handling of these operations by the CPU.

  -> Thus, the higher count for the double precision version is likely due to more SIMD instructions being executed to accomplish the same computational task, as `doubles` utilize vector registers less efficiently than `floats`.

Comparison with Exercise 1:
- How does the solution for this exercise compare to Exercise 1?
  Auto-Vectorization and OpenMP are nearly identical in performance.

Advantages and Disadvantages:
- Advantages: Better because you don't need compiler flags and you know which loops are vectorized.
- Disadvantages: None that we found.

